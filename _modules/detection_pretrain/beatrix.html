<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>detection_pretrain.beatrix &mdash; BackdoorBench v2 documentation</title>
      <link rel="stylesheet" type="text/css" href="/static/_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="/static/_static/css/mytheme.css" />

  
    <link rel="shortcut icon" href="/static/_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="/static/_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="/static/_static/documentation_options.js"></script>
        <script src="/static/_static/jquery.js"></script>
        <script src="/static/_static/underscore.js"></script>
        <script src="/static/_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="/static/_static/doctools.js"></script>
        <script src="/static/_static/js/version_alert.js"></script>
    <script src="/static/_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="/static/_static/pyg_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../start/installation.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../start/quickstart.html">Quick Start by Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/bddataset.html">Build Your Own Backdoor Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/attack.html">Build Your Own Backdoor Attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/defense.html">Build Your Own Backdoor Defense</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PACKAGE REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules/attack.html">packages of attack and defense</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Visualization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../visualization/analysis_readme.html">Analysis Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../visualization/Demo_FV.html">Demo_FV</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">BackdoorBench</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">detection_pretrain.beatrix</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for detection_pretrain.beatrix</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">defense.base</span> <span class="kn">import</span> <span class="n">defense</span>
<span class="c1"># &#39;&#39;&#39;</span>
<span class="c1"># This file is modified based on the following source:</span>
<span class="c1"># link : https://github.com/wanlunsec/Beatrix/blob/master/defenses/Beatrix/Beatrix.py</span>
<span class="c1"># The detection method is called Beatrix.</span>
<span class="c1">#</span>
<span class="c1"># basic sturcture for defense method:</span>
<span class="c1">#     1. basic setting: args</span>
<span class="c1">#     2. attack result(model, train data, test data)</span>
<span class="c1">#     3. Beatrix detection:</span>
<span class="c1">#         a. extract features of clean samples.</span>
<span class="c1">#         b. extract features of poisoned samples.</span>
<span class="c1">#         c. analyze features by Gram Matrices.</span>
<span class="c1">#         d. measure deviations and compute the threshold.</span>
<span class="c1">#         e. detect poisoned samples by threshold.</span>
<span class="c1">#     4. compute TPR and FPR</span>
<span class="c1"># &#39;&#39;&#39;</span>
<span class="c1"># import argparse</span>
<span class="c1"># import os,sys</span>
<span class="c1"># import numpy as np</span>
<span class="c1"># import torch</span>
<span class="c1"># import torch.nn as nn</span>
<span class="c1"># sys.path.append(&#39;../&#39;)</span>
<span class="c1"># sys.path.append(os.getcwd())</span>
<span class="c1">#</span>
<span class="c1"># from sklearn.utils import shuffle</span>
<span class="c1"># from pprint import  pformat</span>
<span class="c1"># import yaml</span>
<span class="c1"># import logging</span>
<span class="c1"># import time</span>
<span class="c1"># from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING</span>
<span class="c1"># from defense.base import defense</span>
<span class="c1"># import scipy</span>
<span class="c1"># from utils.aggregate_block.train_settings_generate import argparser_criterion, argparser_opt_scheduler</span>
<span class="c1"># from utils.trainer_cls import PureCleanModelTrainer</span>
<span class="c1"># from utils.aggregate_block.fix_random import fix_random</span>
<span class="c1"># from utils.aggregate_block.model_trainer_generate import generate_cls_model</span>
<span class="c1"># from utils.log_assist import get_git_info</span>
<span class="c1"># from utils.aggregate_block.dataset_and_transform_generate import get_input_shape, get_num_classes, get_transform</span>
<span class="c1"># from utils.save_load_attack import load_attack_result, save_defense_result</span>
<span class="c1"># from utils.nCHW_nHWC import *</span>
<span class="c1"># import torch.nn.functional as F</span>
<span class="c1"># import tqdm</span>
<span class="c1"># import heapq</span>
<span class="c1"># from PIL import Image</span>
<span class="c1"># from utils.bd_dataset_v2 import dataset_wrapper_with_transform,xy_iter, prepro_cls_DatasetBD_v2</span>
<span class="c1"># from utils.trainer_cls import Metric_Aggregator, PureCleanModelTrainer, all_acc, general_plot_for_epoch, given_dataloader_test</span>
<span class="c1"># from collections import Counter</span>
<span class="c1"># import copy</span>
<span class="c1"># from torch.utils.data import DataLoader</span>
<span class="c1"># from sklearn.metrics import confusion_matrix</span>
<span class="c1"># import csv</span>
<span class="c1"># from sklearn import metrics</span>
<span class="c1"># def cal(true, pred):</span>
<span class="c1">#     TN, FP, FN, TP = confusion_matrix(true, pred).ravel()</span>
<span class="c1">#     return TN, FP, FN, TP</span>
<span class="c1"># def metrix(TN, FP, FN, TP):</span>
<span class="c1">#     TPR = TP/(TP+FN)</span>
<span class="c1">#     FPR = FP/(FP+TN)</span>
<span class="c1">#     precision = TP/(TP+FP)</span>
<span class="c1">#     acc = (TP+TN)/(TN+FP+FN+TP)</span>
<span class="c1">#     return TPR, FPR, precision, acc</span>
<span class="c1">#</span>
<span class="c1"># def threshold_determine(clean_feature_target, ood_detection):</span>
<span class="c1">#     test_deviations_list = []</span>
<span class="c1">#     step = 5</span>
<span class="c1">#     for i in range(step):</span>
<span class="c1">#         index_mask = np.ones((len(clean_feature_target),))</span>
<span class="c1">#         index_mask[i*int(len(clean_feature_target)//step):(i+1)*int(len(clean_feature_target)//step)] = 0</span>
<span class="c1">#         clean_feature_target_train= clean_feature_target[np.where(index_mask == 1)]</span>
<span class="c1">#         clean_feature_target_test = clean_feature_target[np.where(index_mask == 0)]</span>
<span class="c1">#         ood_detection.train(in_data=[clean_feature_target_train],)</span>
<span class="c1">#         test_deviations = ood_detection.get_deviations_([clean_feature_target_test])</span>
<span class="c1">#         test_deviations_list.append(test_deviations)</span>
<span class="c1">#     test_deviations = np.concatenate(test_deviations_list,0)</span>
<span class="c1">#     test_deviations_sort = np.sort(test_deviations,0)</span>
<span class="c1">#     percentile_95 = test_deviations_sort[int(len(test_deviations_sort)*0.95)][0]</span>
<span class="c1">#     percentile_99 = test_deviations_sort[int(len(test_deviations_sort)*0.99)][0]</span>
<span class="c1">#     return percentile_95, percentile_99</span>
<span class="c1">#</span>
<span class="c1"># def gaussian_kernel(x1, x2, kernel_mul=2.0, kernel_num=5, fix_sigma=0, mean_sigma=0):</span>
<span class="c1">#     x1_sample_size = x1.shape[0]</span>
<span class="c1">#     x2_sample_size = x2.shape[0]</span>
<span class="c1">#     x1_tile_shape = []</span>
<span class="c1">#     x2_tile_shape = []</span>
<span class="c1">#     norm_shape = []</span>
<span class="c1">#     for i in range(len(x1.shape) + 1):</span>
<span class="c1">#         if i == 1:</span>
<span class="c1">#             x1_tile_shape.append(x2_sample_size)</span>
<span class="c1">#         else:</span>
<span class="c1">#             x1_tile_shape.append(1)</span>
<span class="c1">#         if i == 0:</span>
<span class="c1">#             x2_tile_shape.append(x1_sample_size)</span>
<span class="c1">#         else:</span>
<span class="c1">#             x2_tile_shape.append(1)</span>
<span class="c1">#         if not (i == 0 or i == 1):</span>
<span class="c1">#             norm_shape.append(i)</span>
<span class="c1">#</span>
<span class="c1">#     tile_x1 = torch.unsqueeze(x1, 1).repeat(x1_tile_shape)</span>
<span class="c1">#     tile_x2 = torch.unsqueeze(x2, 0).repeat(x2_tile_shape)</span>
<span class="c1">#     L2_distance = torch.square(tile_x1 - tile_x2).sum(dim=norm_shape)</span>
<span class="c1">#     if fix_sigma:</span>
<span class="c1">#         bandwidth = fix_sigma</span>
<span class="c1">#     elif mean_sigma:</span>
<span class="c1">#         bandwidth = torch.mean(L2_distance)</span>
<span class="c1">#     else:</span>
<span class="c1">#         bandwidth = torch.median(L2_distance.reshape(L2_distance.shape[0],-1))</span>
<span class="c1">#     bandwidth /= kernel_mul ** (kernel_num // 2)</span>
<span class="c1">#     bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]</span>
<span class="c1">#     print(bandwidth_list)</span>
<span class="c1">#     kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]</span>
<span class="c1">#     return sum(kernel_val)</span>
<span class="c1">#</span>
<span class="c1"># def kmmd_dist(x1, x2):</span>
<span class="c1">#     X_total = torch.cat([x1,x2],0)</span>
<span class="c1">#     Gram_matrix = gaussian_kernel(X_total,X_total,kernel_mul=2.0, kernel_num=2, fix_sigma=0, mean_sigma=0)</span>
<span class="c1">#     n = int(x1.shape[0])</span>
<span class="c1">#     m = int(x2.shape[0])</span>
<span class="c1">#     x1x1 = Gram_matrix[:n, :n]</span>
<span class="c1">#     x2x2 = Gram_matrix[n:, n:]</span>
<span class="c1">#     x1x2 = Gram_matrix[:n, n:]</span>
<span class="c1">#     diff = torch.mean(x1x1) + torch.mean(x2x2) - 2 * torch.mean(x1x2)</span>
<span class="c1">#     diff = (m*n)/(m+n)*diff</span>
<span class="c1">#     return diff.cpu().numpy()</span>
<span class="c1">#</span>
<span class="c1"># class Feature_Correlations:</span>
<span class="c1">#     def __init__(self,POWER_list, mode=&#39;mad&#39;):</span>
<span class="c1">#         self.power = POWER_list</span>
<span class="c1">#         self.mode = mode</span>
<span class="c1">#</span>
<span class="c1">#     def train(self, in_data):</span>
<span class="c1">#         self.in_data = in_data</span>
<span class="c1">#         if &#39;mad&#39; in self.mode:</span>
<span class="c1">#             self.medians, self.mads = self.get_median_mad(self.in_data)</span>
<span class="c1">#             self.mins, self.maxs = self.minmax_mad()</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#     def minmax_mad(self):</span>
<span class="c1">#         mins = []</span>
<span class="c1">#         maxs = []</span>
<span class="c1">#         for L, mm in enumerate(zip(self.medians,self.mads)):</span>
<span class="c1">#             medians, mads = mm[0], mm[1]</span>
<span class="c1">#             if L==len(mins):</span>
<span class="c1">#                 mins.append([None]*len(self.power))</span>
<span class="c1">#                 maxs.append([None]*len(self.power))</span>
<span class="c1">#             for p, P in enumerate(self.power):</span>
<span class="c1">#                     mins[L][p] = medians[p]-mads[p]*10</span>
<span class="c1">#                     maxs[L][p] = medians[p]+mads[p]*10</span>
<span class="c1">#         return mins, maxs</span>
<span class="c1">#</span>
<span class="c1">#     def G_p(self, ob, p):</span>
<span class="c1">#         temp = ob.detach()</span>
<span class="c1">#         temp = temp.reshape(temp.shape[0],temp.shape[1],-1)</span>
<span class="c1">#         temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1))))</span>
<span class="c1">#         temp = temp.triu()</span>
<span class="c1">#         temp = temp.sign()*torch.abs(temp)**(1/p)</span>
<span class="c1">#         temp = temp.reshape(temp.shape[0],-1)</span>
<span class="c1">#         self.num_feature = temp.shape[-1]/2</span>
<span class="c1">#         return temp</span>
<span class="c1">#</span>
<span class="c1">#     def get_median_mad(self, feat_list):</span>
<span class="c1">#         medians = []</span>
<span class="c1">#         mads = []</span>
<span class="c1">#         for L,feat_L in enumerate(feat_list):</span>
<span class="c1">#             if L==len(medians):</span>
<span class="c1">#                 medians.append([None]*len(self.power))</span>
<span class="c1">#                 mads.append([None]*len(self.power))</span>
<span class="c1">#             for p,P in enumerate(self.power):</span>
<span class="c1">#                 g_p = self.G_p(feat_L,P)</span>
<span class="c1">#                 current_median = g_p.median(dim=0,keepdim=True)[0]</span>
<span class="c1">#                 current_mad = torch.abs(g_p - current_median).median(dim=0,keepdim=True)[0]</span>
<span class="c1">#                 medians[L][p] = current_median</span>
<span class="c1">#                 mads[L][p] = current_mad</span>
<span class="c1">#         return medians, mads</span>
<span class="c1">#</span>
<span class="c1">#     def get_deviations_(self, feat_list):</span>
<span class="c1">#         deviations = []</span>
<span class="c1">#         batch_deviations = []</span>
<span class="c1">#         for L,feat_L in enumerate(feat_list):</span>
<span class="c1">#             dev = 0</span>
<span class="c1">#             for p,P in enumerate(self.power):</span>
<span class="c1">#                 g_p = self.G_p(feat_L,P)</span>
<span class="c1">#                 dev +=  (F.relu(self.mins[L][p]-g_p)/torch.abs(self.mins[L][p]+10**-6)).sum(dim=1,keepdim=True)</span>
<span class="c1">#                 dev +=  (F.relu(g_p-self.maxs[L][p])/torch.abs(self.maxs[L][p]+10**-6)).sum(dim=1,keepdim=True)</span>
<span class="c1">#             batch_deviations.append(dev.cpu().detach().numpy())</span>
<span class="c1">#         batch_deviations = np.concatenate(batch_deviations,axis=1)</span>
<span class="c1">#         deviations.append(batch_deviations)</span>
<span class="c1">#         deviations = np.concatenate(deviations,axis=0) /self.num_feature /len(self.power)</span>
<span class="c1">#         return deviations</span>
<span class="c1">#</span>
<span class="c1">#     def get_deviations(self, feat_list):</span>
<span class="c1">#         deviations = []</span>
<span class="c1">#         batch_deviations = []</span>
<span class="c1">#         for L,feat_L in enumerate(feat_list):</span>
<span class="c1">#             dev = 0</span>
<span class="c1">#             for p,P in enumerate(self.power):</span>
<span class="c1">#                 g_p = self.G_p(feat_L,P)</span>
<span class="c1">#                 dev += torch.sum(torch.abs(g_p-self.medians[L][p])/(self.mads[L][p]+1e-6),dim=1,keepdim=True)</span>
<span class="c1">#             batch_deviations.append(dev.cpu().detach().numpy())</span>
<span class="c1">#         batch_deviations = np.concatenate(batch_deviations,axis=1)</span>
<span class="c1">#         deviations.append(batch_deviations)</span>
<span class="c1">#         deviations = np.concatenate(deviations,axis=0)/self.num_feature /len(self.power)</span>
<span class="c1">#         return deviations</span>
<span class="c1">#</span>
<span class="c1"># class LayerActivations:</span>
<span class="c1">#     def __init__(self, model,args):</span>
<span class="c1">#         self.args = args</span>
<span class="c1">#         self.model = model</span>
<span class="c1">#         self.model.eval()</span>
<span class="c1">#         self.build_hook()</span>
<span class="c1">#</span>
<span class="c1">#     def build_hook(self):</span>
<span class="c1">#         module_dict = dict(self.model.named_modules())</span>
<span class="c1">#         target_layer = module_dict[args.target_layer]</span>
<span class="c1">#         self.hook = target_layer.register_forward_hook(self.hook_fn)</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#     def hook_fn(self, module, input, output):</span>
<span class="c1">#         self.features = input[0]</span>
<span class="c1">#         # self.features = output</span>
<span class="c1">#</span>
<span class="c1">#     def remove_hook(self):</span>
<span class="c1">#         self.hook.remove()</span>
<span class="c1">#</span>
<span class="c1">#     def run_hook(self,x):</span>
<span class="c1">#         self.model(x)</span>
<span class="c1">#         # self.remove_hook()</span>
<span class="c1">#         return self.features</span>
<span class="c1">#</span>

<div class="viewcode-block" id="beatrix"><a class="viewcode-back" href="../../generated/detection_pretrain.beatrix.html#detection_pretrain.beatrix">[docs]</a><span class="k">class</span> <span class="nc">beatrix</span><span class="p">(</span><span class="n">defense</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;The Beatrix Resurrections: Robust Backdoor Detection via Gram Matrices</span>

<span class="sd">    basic sturcture for defense method:</span>

<span class="sd">    1. basic setting: args</span>
<span class="sd">    2. attack result(model, train data, test data)</span>
<span class="sd">    3. Beatrix detection:</span>
<span class="sd">        a. extract features of clean samples.</span>
<span class="sd">        b. extract features of poisoned samples.</span>
<span class="sd">        c. analyze features by Gram Matrices.</span>
<span class="sd">        d. measure deviations and compute the threshold.</span>
<span class="sd">        e. detect poisoned samples by threshold.</span>
<span class="sd">    4. compute TPR and FPR</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        parser = argparse.ArgumentParser(description=sys.argv[0])</span>
<span class="sd">        beatrix.add_arguments(parser)</span>
<span class="sd">        args = parser.parse_args()</span>
<span class="sd">        beatrix_method = beatrix(args)</span>
<span class="sd">        if &quot;result_file&quot; not in args.__dict__:</span>
<span class="sd">            args.result_file = &#39;defense_test_badnet&#39;</span>
<span class="sd">        elif args.result_file is None:</span>
<span class="sd">            args.result_file = &#39;defense_test_badnet&#39;</span>
<span class="sd">        result = beatrix_method.detection(args.result_file)</span>

<span class="sd">    .. Note::</span>
<span class="sd">        @article{ma2022beatrix,</span>
<span class="sd">          title={The&quot; Beatrix&#39;&#39;Resurrections: Robust Backdoor Detection via Gram Matrices},</span>
<span class="sd">          author={Ma, Wanlun and Wang, Derui and Sun, Ruoxi and Xue, Minhui and Wen, Sheng and Xiang, Yang},</span>
<span class="sd">          journal={arXiv preprint arXiv:2209.11715},</span>
<span class="sd">          year={2022}}</span>

<span class="sd">    Args:</span>
<span class="sd">        baisc args: in the base class</span>
<span class="sd">        target_layer(str): which layer for detection</span>
<span class="sd">        &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">args</span><span class="p">):</span>
        <span class="k">pass</span></div>
<span class="c1">#         with open(args.yaml_path, &#39;r&#39;) as f:</span>
<span class="c1">#             defaults = yaml.safe_load(f)</span>
<span class="c1">#</span>
<span class="c1">#         defaults.update({k:v for k,v in args.__dict__.items() if v is not None})</span>
<span class="c1">#</span>
<span class="c1">#         args.__dict__ = defaults</span>
<span class="c1">#</span>
<span class="c1">#         args.terminal_info = sys.argv</span>
<span class="c1">#</span>
<span class="c1">#         args.num_classes = get_num_classes(args.dataset)</span>
<span class="c1">#         args.input_height, args.input_width, args.input_channel = get_input_shape(args.dataset)</span>
<span class="c1">#         args.img_size = (args.input_height, args.input_width, args.input_channel)</span>
<span class="c1">#         args.dataset_path = f&quot;{args.dataset_path}/{args.dataset}&quot;</span>
<span class="c1">#</span>
<span class="c1">#         self.args = args</span>
<span class="c1">#</span>
<span class="c1">#         if &#39;result_file&#39; in args.__dict__ :</span>
<span class="c1">#             if args.result_file is not None:</span>
<span class="c1">#                 self.set_result(args.result_file)</span>
<span class="c1">#</span>
<span class="c1">#     def add_arguments(parser):</span>
<span class="c1">#         parser.add_argument(&#39;--device&#39;, type=str, help=&#39;cuda, cpu&#39;)</span>
<span class="c1">#         parser.add_argument(&quot;-pm&quot;,&quot;--pin_memory&quot;, type=lambda x: str(x) in [&#39;True&#39;, &#39;true&#39;, &#39;1&#39;], help = &quot;dataloader pin_memory&quot;)</span>
<span class="c1">#         parser.add_argument(&quot;-nb&quot;,&quot;--non_blocking&quot;, type=lambda x: str(x) in [&#39;True&#39;, &#39;true&#39;, &#39;1&#39;], help = &quot;.to(), set the non_blocking = ?&quot;)</span>
<span class="c1">#         parser.add_argument(&quot;-pf&quot;, &#39;--prefetch&#39;, type=lambda x: str(x) in [&#39;True&#39;, &#39;true&#39;, &#39;1&#39;], help=&#39;use prefetch&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--amp&#39;, default = False, type=lambda x: str(x) in [&#39;True&#39;,&#39;true&#39;,&#39;1&#39;])</span>
<span class="c1">#</span>
<span class="c1">#         parser.add_argument(&#39;--checkpoint_load&#39;, type=str, help=&#39;the location of load model&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--checkpoint_save&#39;, type=str, help=&#39;the location of checkpoint where model is saved&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--log&#39;, type=str, help=&#39;the location of log&#39;)</span>
<span class="c1">#         parser.add_argument(&quot;--dataset_path&quot;, type=str, help=&#39;the location of data&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--dataset&#39;, type=str, help=&#39;mnist, cifar10, cifar100, gtrsb, tiny&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--result_file&#39;, type=str, help=&#39;the location of result&#39;)</span>
<span class="c1">#</span>
<span class="c1">#         parser.add_argument(&#39;--epochs&#39;, type=int)</span>
<span class="c1">#         parser.add_argument(&#39;--batch_size&#39;, type=int)</span>
<span class="c1">#         parser.add_argument(&quot;--num_workers&quot;, type=float)</span>
<span class="c1">#         parser.add_argument(&#39;--lr&#39;, type=float)</span>
<span class="c1">#         parser.add_argument(&#39;--lr_scheduler&#39;, type=str, help=&#39;the scheduler of lr&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--steplr_stepsize&#39;, type=int)</span>
<span class="c1">#         parser.add_argument(&#39;--steplr_gamma&#39;, type=float)</span>
<span class="c1">#         parser.add_argument(&#39;--steplr_milestones&#39;, type=list)</span>
<span class="c1">#         parser.add_argument(&#39;--model&#39;, type=str, help=&#39;resnet18&#39;)</span>
<span class="c1">#</span>
<span class="c1">#         parser.add_argument(&#39;--client_optimizer&#39;, type=int)</span>
<span class="c1">#         parser.add_argument(&#39;--sgd_momentum&#39;, type=float)</span>
<span class="c1">#         parser.add_argument(&#39;--wd&#39;, type=float, help=&#39;weight decay of sgd&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--frequency_save&#39;, type=int,</span>
<span class="c1">#                         help=&#39; frequency_save, 0 is never&#39;)</span>
<span class="c1">#</span>
<span class="c1">#         parser.add_argument(&#39;--random_seed&#39;, type=int, help=&#39;random seed&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--yaml_path&#39;, type=str, default=&quot;./config/detection/beatrix/cifar10.yaml&quot;, help=&#39;the path of yaml&#39;)</span>
<span class="c1">#         parser.add_argument(&#39;--clean_sample_num&#39;, type=int)</span>
<span class="c1">#         parser.add_argument(&#39;--target_layer&#39;, type=str)</span>
<span class="c1">#</span>
<span class="c1">#     def set_result(self, result_file):</span>
<span class="c1">#         attack_file = &#39;record/&#39; + result_file</span>
<span class="c1">#         save_path = &#39;record/&#39; + result_file + &#39;/detection/beatrix_pretrain/&#39;</span>
<span class="c1">#         if not (os.path.exists(save_path)):</span>
<span class="c1">#                 os.makedirs(save_path)</span>
<span class="c1">#         self.args.save_path = save_path</span>
<span class="c1">#         if self.args.checkpoint_save is None:</span>
<span class="c1">#             self.args.checkpoint_save = save_path + &#39;detection_info/&#39;</span>
<span class="c1">#             if not (os.path.exists(self.args.checkpoint_save)):</span>
<span class="c1">#                 os.makedirs(self.args.checkpoint_save)</span>
<span class="c1">#</span>
<span class="c1">#         if self.args.log is None:</span>
<span class="c1">#             self.args.log = save_path + &#39;log/&#39;</span>
<span class="c1">#             if not (os.path.exists(self.args.log)):</span>
<span class="c1">#                 os.makedirs(self.args.log)</span>
<span class="c1">#         self.result = load_attack_result(attack_file + &#39;/attack_result.pt&#39;)</span>
<span class="c1">#</span>
<span class="c1">#     def set_trainer(self, model):</span>
<span class="c1">#         self.trainer = PureCleanModelTrainer(</span>
<span class="c1">#             model = model,</span>
<span class="c1">#         )</span>
<span class="c1">#</span>
<span class="c1">#     def set_logger(self):</span>
<span class="c1">#         args = self.args</span>
<span class="c1">#         logFormatter = logging.Formatter(</span>
<span class="c1">#             fmt=&#39;%(asctime)s [%(levelname)-8s] [%(filename)s:%(lineno)d] %(message)s&#39;,</span>
<span class="c1">#             datefmt=&#39;%Y-%m-%d:%H:%M:%S&#39;,</span>
<span class="c1">#         )</span>
<span class="c1">#         logger = logging.getLogger()</span>
<span class="c1">#</span>
<span class="c1">#         fileHandler = logging.FileHandler(args.log + &#39;/&#39; + time.strftime(&quot;%Y_%m_%d_%H_%M_%S&quot;, time.localtime()) + &#39;.log&#39;)</span>
<span class="c1">#         fileHandler.setFormatter(logFormatter)</span>
<span class="c1">#         logger.addHandler(fileHandler)</span>
<span class="c1">#</span>
<span class="c1">#         consoleHandler = logging.StreamHandler()</span>
<span class="c1">#         consoleHandler.setFormatter(logFormatter)</span>
<span class="c1">#         logger.addHandler(consoleHandler)</span>
<span class="c1">#</span>
<span class="c1">#         logger.setLevel(logging.INFO)</span>
<span class="c1">#         logging.info(pformat(args.__dict__))</span>
<span class="c1">#</span>
<span class="c1">#         try:</span>
<span class="c1">#             logging.info(pformat(get_git_info()))</span>
<span class="c1">#         except:</span>
<span class="c1">#             logging.info(&#39;Getting git info fails.&#39;)</span>
<span class="c1">#</span>
<span class="c1">#     def set_devices(self):</span>
<span class="c1">#         self.device = self.args.device</span>
<span class="c1">#</span>
<span class="c1">#     def get_feature_predict(self, dataset, model, intermedia_feature):</span>
<span class="c1">#         model.eval()</span>
<span class="c1">#         data_loader = DataLoader(dataset, self.args.batch_size, shuffle=False)</span>
<span class="c1">#         features = []</span>
<span class="c1">#         preds_label = []</span>
<span class="c1">#         for i, (input, label) in enumerate(data_loader):</span>
<span class="c1">#             input = input.to(self.args.device)</span>
<span class="c1">#             label = label.to(self.args.device)</span>
<span class="c1">#             features.append(intermedia_feature.run_hook(input).detach().cpu())</span>
<span class="c1">#             output = model(input)</span>
<span class="c1">#             preds_label.append(torch.argmax(output, 1).detach().cpu())</span>
<span class="c1">#</span>
<span class="c1">#         preds_label = torch.cat(preds_label,axis=0)</span>
<span class="c1">#         features = torch.cat(features,axis=0)</span>
<span class="c1">#         return features, preds_label</span>
<span class="c1">#</span>
<span class="c1">#     def filtering(self):</span>
<span class="c1">#         start = time.perf_counter()</span>
<span class="c1">#         self.set_devices()</span>
<span class="c1">#         fix_random(self.args.random_seed)</span>
<span class="c1">#</span>
<span class="c1">#         ### a. load model, bd train data and transforms</span>
<span class="c1">#         model = generate_cls_model(self.args.model,self.args.num_classes)</span>
<span class="c1">#         model.load_state_dict(self.result[&#39;model&#39;])</span>
<span class="c1">#         if &quot;,&quot; in self.device:</span>
<span class="c1">#             model = torch.nn.DataParallel(</span>
<span class="c1">#                 model,</span>
<span class="c1">#                 device_ids=[int(i) for i in self.args.device[5:].split(&quot;,&quot;)]  # eg. &quot;cuda:2,3,7&quot; -&gt; [2,3,7]</span>
<span class="c1">#             )</span>
<span class="c1">#             self.args.device = f&#39;cuda:{model.device_ids[0]}&#39;</span>
<span class="c1">#             model.to(self.args.device)</span>
<span class="c1">#             model.eval()</span>
<span class="c1">#         else:</span>
<span class="c1">#             model.to(self.args.device)</span>
<span class="c1">#             model.eval()</span>
<span class="c1">#</span>
<span class="c1">#         test_tran = get_transform(self.args.dataset, *([self.args.input_height,self.args.input_width]) , train = False)</span>
<span class="c1">#         intermedia_feature = LayerActivations(model.to(self.args.device),self.args)</span>
<span class="c1">#         bd_train_dataset = self.result[&#39;bd_train&#39;].wrapped_dataset</span>
<span class="c1">#         pindex = np.where(np.array(bd_train_dataset.poison_indicator) == 1)[0]</span>
<span class="c1">#</span>
<span class="c1">#         clean_test_dataset = self.result[&#39;clean_test&#39;].wrapped_dataset</span>
<span class="c1">#</span>
<span class="c1">#         ### b. find a clean sample from test dataset</span>
<span class="c1">#         images = []</span>
<span class="c1">#         labels = []</span>
<span class="c1">#         for img, label in clean_test_dataset:</span>
<span class="c1">#             images.append(img)</span>
<span class="c1">#             labels.append(label)</span>
<span class="c1">#</span>
<span class="c1">#         test_dataset = xy_iter(images, labels,transform=test_tran)</span>
<span class="c1">#         data_clean_loader = DataLoader(test_dataset, batch_size=self.args.batch_size,drop_last=False, shuffle=False,pin_memory=False)</span>
<span class="c1">#         result = []</span>
<span class="c1">#         with torch.no_grad():</span>
<span class="c1">#             for batch_idx, (input, label) in enumerate(data_clean_loader):</span>
<span class="c1">#</span>
<span class="c1">#                 input, label = input.to(self.args.device), label.to(self.args.device)</span>
<span class="c1">#                 outputs = model(input)</span>
<span class="c1">#                 _, predicted = outputs.max(1)</span>
<span class="c1">#                 result.append(predicted.cpu().numpy())</span>
<span class="c1">#         result = np.concatenate(result, axis=0)</span>
<span class="c1">#</span>
<span class="c1">#         labels = result</span>
<span class="c1">#         class_idx_whole = []</span>
<span class="c1">#         num = int(self.args.clean_sample_num / self.args.num_classes)</span>
<span class="c1">#         if num == 0:</span>
<span class="c1">#             num = 1</span>
<span class="c1">#         for i in range(self.args.num_classes):</span>
<span class="c1">#             class_idx_whole.append(np.random.choice(np.where(np.array(labels)==i)[0], num))</span>
<span class="c1">#         class_idx_whole = np.concatenate(class_idx_whole, axis=0)</span>
<span class="c1">#         image_c = [images[i] for i in class_idx_whole]</span>
<span class="c1">#         label_c = [labels[i] for i in class_idx_whole]</span>
<span class="c1">#</span>
<span class="c1">#         ## c. get clean feature and pred label</span>
<span class="c1">#         clean_dataset = xy_iter(image_c, label_c,transform=test_tran)</span>
<span class="c1">#         clean_features, clean_preditions = self.get_feature_predict(clean_dataset, model, intermedia_feature)</span>
<span class="c1">#         (clean_features, clean_preditions) = shuffle(clean_features, clean_preditions)</span>
<span class="c1">#</span>
<span class="c1">#         ## d. use gram-matrix OOD detection</span>
<span class="c1">#         self.order_list = [1,2,3,4,5,6,7,8]</span>
<span class="c1">#         ood_detection = Feature_Correlations(POWER_list=self.order_list,mode=&#39;mad&#39;)</span>
<span class="c1">#</span>
<span class="c1">#         ## e. load training data with poison samples</span>
<span class="c1">#         images_poison = []</span>
<span class="c1">#         labels_poison = []</span>
<span class="c1">#         for img, label, _,_,_ in bd_train_dataset:</span>
<span class="c1">#             images_poison.append(img)</span>
<span class="c1">#             labels_poison.append(label)</span>
<span class="c1">#</span>
<span class="c1">#         ## f. get training feature and pred label</span>
<span class="c1">#         train_dataset = xy_iter(images_poison, labels_poison,transform=test_tran)</span>
<span class="c1">#         train_features, train_preditions = self.get_feature_predict(train_dataset, model, intermedia_feature)</span>
<span class="c1">#         # (train_features, train_preditions) = shuffle(train_features, train_preditions)</span>
<span class="c1">#</span>
<span class="c1">#         threshold_list = []</span>
<span class="c1">#         suspect_index_95 = []</span>
<span class="c1">#         suspect_index_99 = []</span>
<span class="c1">#         J_t = []</span>
<span class="c1">#         for test_target_label in range(args.num_classes):</span>
<span class="c1">#             print(f&#39;*****class:{test_target_label}*****&#39;)</span>
<span class="c1">#             clean_feature_defend = clean_features[np.where(clean_preditions==test_target_label)]</span>
<span class="c1">#</span>
<span class="c1">#             threshold_95, threshold_99 = threshold_determine(clean_feature_defend, ood_detection)</span>
<span class="c1">#             threshold_list.append([test_target_label,threshold_95, threshold_99])</span>
<span class="c1">#</span>
<span class="c1">#             ood_detection.train(in_data=[clean_feature_defend])</span>
<span class="c1">#</span>
<span class="c1">#             class_idx_current = np.where(train_preditions==test_target_label)[0]</span>
<span class="c1">#             class_feature_test = train_features[class_idx_current]</span>
<span class="c1">#             class_test_deviations = ood_detection.get_deviations_([class_feature_test])</span>
<span class="c1">#</span>
<span class="c1">#             ood_label_95 = np.where(class_test_deviations &gt; threshold_95)[0]</span>
<span class="c1">#             ood_label_99 = np.where(class_test_deviations &gt; threshold_99)[0]</span>
<span class="c1">#</span>
<span class="c1">#             suspect_index_95.append(class_idx_current[ood_label_95])</span>
<span class="c1">#             suspect_index_99.append(class_idx_current[ood_label_99])</span>
<span class="c1">#</span>
<span class="c1">#             ### find target label start###</span>
<span class="c1">#             ood_label_95 = np.where(class_test_deviations &gt; threshold_95, 1, 0).squeeze()</span>
<span class="c1">#             ood_label_99 = np.where(class_test_deviations &gt; threshold_99, 1, 0).squeeze()</span>
<span class="c1">#</span>
<span class="c1">#             clean_feature_group = class_feature_test[np.where(ood_label_95==0)]</span>
<span class="c1">#             bd_feature_group = class_feature_test[np.where(ood_label_95==1)]</span>
<span class="c1">#             clean_feature_flat = torch.mean(clean_feature_group,dim=(2,3))</span>
<span class="c1">#             bd_feature_flat = torch.mean(bd_feature_group,dim=(2,3))</span>
<span class="c1">#             if bd_feature_flat.shape[0] &lt; 1:</span>
<span class="c1">#                 kmmd = np.array([0.0])</span>
<span class="c1">#             else:</span>
<span class="c1">#                 kmmd = kmmd_dist(clean_feature_flat[:500], bd_feature_flat[:500])</span>
<span class="c1">#             print(f&#39;KMMD:{kmmd.item()}.&#39;)</span>
<span class="c1">#</span>
<span class="c1">#             J_t.append(kmmd.item())</span>
<span class="c1">#</span>
<span class="c1">#         J_t = np.asarray(J_t)</span>
<span class="c1">#         J_t_median = np.median(J_t)</span>
<span class="c1">#         J_MAD = np.median(np.abs(J_t - J_t_median))</span>
<span class="c1">#         J_star = np.abs(J_t - J_t_median)/1.4826/(J_MAD+1e-6)</span>
<span class="c1">#</span>
<span class="c1">#         flag_list = []</span>
<span class="c1">#         for i,J_star_i in enumerate(J_star):</span>
<span class="c1">#             if J_star_i&gt;np.exp(2):</span>
<span class="c1">#                 flag_list.append([i,J_star_i])</span>
<span class="c1">#         logging.info(&quot;Flagged label list: {}&quot;.format(&quot;,&quot;.join([&quot;{}: {}&quot;.format(y_label, J_s) for y_label, J_s in flag_list])))</span>
<span class="c1">#         ### find target label end###</span>
<span class="c1">#</span>
<span class="c1">#         suspect_index_95 = np.concatenate(suspect_index_95, axis=0)</span>
<span class="c1">#</span>
<span class="c1">#         true_index = np.zeros(len(images_poison))</span>
<span class="c1">#         for i in range(len(true_index)):</span>
<span class="c1">#             if i in pindex:</span>
<span class="c1">#                 true_index[i] = 1</span>
<span class="c1">#         if len(suspect_index_95)==0:</span>
<span class="c1">#             tn = len(true_index) - np.sum(true_index)</span>
<span class="c1">#             fp = np.sum(true_index)</span>
<span class="c1">#             fn = 0</span>
<span class="c1">#             tp = 0</span>
<span class="c1">#             f = open(self.args.save_path + &#39;/detection_info.csv&#39;, &#39;a&#39;, encoding=&#39;utf-8&#39;)</span>
<span class="c1">#             csv_write = csv.writer(f)</span>
<span class="c1">#             csv_write.writerow([&#39;record&#39;, &#39;TN&#39;,&#39;FP&#39;,&#39;FN&#39;,&#39;TP&#39;,&#39;TPR&#39;,&#39;FPR&#39;, &#39;target&#39;])</span>
<span class="c1">#             csv_write.writerow([args.result_file, tn,fp,fn,tp, 0,0, &#39;None&#39;])</span>
<span class="c1">#             f.close()</span>
<span class="c1">#         else:</span>
<span class="c1">#             findex_95 = np.zeros(len(images_poison))</span>
<span class="c1">#             for i in range(len(findex_95)):</span>
<span class="c1">#                 if i in suspect_index_95:</span>
<span class="c1">#                     findex_95[i] = 1</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#             tn, fp, fn, tp = cal(true_index, findex_95)</span>
<span class="c1">#             TPR, FPR, precision, acc = metrix(tn, fp, fn, tp)</span>
<span class="c1">#             new_TP = tp</span>
<span class="c1">#             new_FN = fn*9</span>
<span class="c1">#             new_FP = fp*1</span>
<span class="c1">#             precision = new_TP / (new_TP + new_FP) if new_TP + new_FP != 0 else 0</span>
<span class="c1">#             recall = new_TP / (new_TP + new_FN) if new_TP + new_FN != 0 else 0</span>
<span class="c1">#             fw1 = 2*(precision * recall)/ (precision + recall) if precision + recall != 0 else 0</span>
<span class="c1">#             end = time.perf_counter()</span>
<span class="c1">#             time_miniute = (end-start)/60</span>
<span class="c1">#</span>
<span class="c1">#             f = open(self.args.save_path + &#39;/detection_info.csv&#39;, &#39;a&#39;, encoding=&#39;utf-8&#39;)</span>
<span class="c1">#             csv_write = csv.writer(f)</span>
<span class="c1">#             csv_write.writerow([&#39;record&#39;, &#39;TN&#39;,&#39;FP&#39;,&#39;FN&#39;,&#39;TP&#39;,&#39;TPR&#39;,&#39;FPR&#39;, &#39;target&#39;])</span>
<span class="c1">#             csv_write.writerow([args.result_file, tn, fp, fn, tp, TPR, FPR, [i for i,j in flag_list]])</span>
<span class="c1">#             f.close()</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#     def detection(self,result_file):</span>
<span class="c1">#         self.set_result(result_file)</span>
<span class="c1">#         self.set_logger()</span>
<span class="c1">#         result = self.filtering()</span>
<span class="c1">#         return result</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1"># if __name__ == &#39;__main__&#39;:</span>
<span class="c1">#     parser = argparse.ArgumentParser(description=sys.argv[0])</span>
<span class="c1">#     beatrix.add_arguments(parser)</span>
<span class="c1">#     args = parser.parse_args()</span>
<span class="c1">#     beatrix_method = beatrix(args)</span>
<span class="c1">#     if &quot;result_file&quot; not in args.__dict__:</span>
<span class="c1">#         args.result_file = &#39;defense_test_badnet&#39;</span>
<span class="c1">#     elif args.result_file is None:</span>
<span class="c1">#         args.result_file = &#39;defense_test_badnet&#39;</span>
<span class="c1">#     result = beatrix_method.detection(args.result_file)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, SCLBD.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>